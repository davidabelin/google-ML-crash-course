{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "My image_classification_part3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jTEzoMx6CasV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidabelin/google-ML-crash-course/blob/main/My%20image_classification_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmPj1VVCfWb"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrbllgAFipZ",
        "outputId": "a16a17a7-2ec5-42ae-bfbd-63b98dcdd3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 19:01:13--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.128, 108.177.12.128, 74.125.26.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  45.3MB/s    in 1.9s    \n",
            "\n",
            "2020-10-29 19:01:15 (45.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj4rXshqbQlS",
        "outputId": "dcb642a5-b697-48da-e4fd-5e0e57413bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg",
        "outputId": "fe577049-a8cc-4988-f960-8c041550db9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4s8HckqGlnb",
        "outputId": "47133990-8e19-4cfa-b4b9-5f7846dd9280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 19:01:25--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 173.194.218.128, 64.233.170.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   119MB/s    in 0.6s    \n",
            "\n",
            "2020-10-29 19:01:25 (119 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl9XXARuV_eg",
        "outputId": "d8ff12e3-f9ca-44d3-8b3e-7c287a6f0bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA",
        "outputId": "8d0f8ec2-3748-4dd9-c662-338962cebe52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-223274cfaaff>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/2\n",
            "100/100 - 20s - loss: 0.3343 - acc: 0.8670 - val_loss: 0.1460 - val_acc: 0.9440\n",
            "Epoch 2/2\n",
            "100/100 - 19s - loss: 0.2112 - acc: 0.9180 - val_loss: 0.1220 - val_acc: 0.9540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_J4S0Z2rgg"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GgDGG4Y_hJ",
        "outputId": "56a6940b-a0df-4efb-cf37-85f9d81ea01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 19s - loss: 0.2147 - acc: 0.9080 - val_loss: 0.1113 - val_acc: 0.9510\n",
            "Epoch 2/50\n",
            "100/100 - 18s - loss: 0.2207 - acc: 0.9110 - val_loss: 0.1152 - val_acc: 0.9500\n",
            "Epoch 3/50\n",
            "100/100 - 19s - loss: 0.2267 - acc: 0.9065 - val_loss: 0.1177 - val_acc: 0.9490\n",
            "Epoch 4/50\n",
            "100/100 - 19s - loss: 0.2164 - acc: 0.9095 - val_loss: 0.1178 - val_acc: 0.9490\n",
            "Epoch 5/50\n",
            "100/100 - 18s - loss: 0.2018 - acc: 0.9190 - val_loss: 0.1181 - val_acc: 0.9490\n",
            "Epoch 6/50\n",
            "100/100 - 18s - loss: 0.2083 - acc: 0.9105 - val_loss: 0.1177 - val_acc: 0.9480\n",
            "Epoch 7/50\n",
            "100/100 - 19s - loss: 0.2112 - acc: 0.9185 - val_loss: 0.1175 - val_acc: 0.9490\n",
            "Epoch 8/50\n",
            "100/100 - 18s - loss: 0.2064 - acc: 0.9200 - val_loss: 0.1167 - val_acc: 0.9500\n",
            "Epoch 9/50\n",
            "100/100 - 19s - loss: 0.2104 - acc: 0.9145 - val_loss: 0.1162 - val_acc: 0.9490\n",
            "Epoch 10/50\n",
            "100/100 - 18s - loss: 0.2085 - acc: 0.9120 - val_loss: 0.1156 - val_acc: 0.9500\n",
            "Epoch 11/50\n",
            "100/100 - 18s - loss: 0.2043 - acc: 0.9235 - val_loss: 0.1151 - val_acc: 0.9500\n",
            "Epoch 12/50\n",
            "100/100 - 18s - loss: 0.2085 - acc: 0.9110 - val_loss: 0.1142 - val_acc: 0.9510\n",
            "Epoch 13/50\n",
            "100/100 - 19s - loss: 0.2024 - acc: 0.9120 - val_loss: 0.1136 - val_acc: 0.9520\n",
            "Epoch 14/50\n",
            "100/100 - 19s - loss: 0.2008 - acc: 0.9145 - val_loss: 0.1132 - val_acc: 0.9530\n",
            "Epoch 15/50\n",
            "100/100 - 18s - loss: 0.1989 - acc: 0.9170 - val_loss: 0.1130 - val_acc: 0.9530\n",
            "Epoch 16/50\n",
            "100/100 - 19s - loss: 0.1868 - acc: 0.9240 - val_loss: 0.1130 - val_acc: 0.9500\n",
            "Epoch 17/50\n",
            "100/100 - 19s - loss: 0.2014 - acc: 0.9195 - val_loss: 0.1124 - val_acc: 0.9520\n",
            "Epoch 18/50\n",
            "100/100 - 19s - loss: 0.1918 - acc: 0.9170 - val_loss: 0.1123 - val_acc: 0.9500\n",
            "Epoch 19/50\n",
            "100/100 - 19s - loss: 0.1978 - acc: 0.9210 - val_loss: 0.1113 - val_acc: 0.9520\n",
            "Epoch 20/50\n",
            "100/100 - 19s - loss: 0.1991 - acc: 0.9135 - val_loss: 0.1110 - val_acc: 0.9520\n",
            "Epoch 21/50\n",
            "100/100 - 18s - loss: 0.2008 - acc: 0.9210 - val_loss: 0.1108 - val_acc: 0.9520\n",
            "Epoch 22/50\n",
            "100/100 - 18s - loss: 0.1892 - acc: 0.9270 - val_loss: 0.1102 - val_acc: 0.9520\n",
            "Epoch 23/50\n",
            "100/100 - 18s - loss: 0.1959 - acc: 0.9215 - val_loss: 0.1102 - val_acc: 0.9520\n",
            "Epoch 24/50\n",
            "100/100 - 18s - loss: 0.1841 - acc: 0.9280 - val_loss: 0.1097 - val_acc: 0.9520\n",
            "Epoch 25/50\n",
            "100/100 - 19s - loss: 0.2069 - acc: 0.9110 - val_loss: 0.1097 - val_acc: 0.9520\n",
            "Epoch 26/50\n",
            "100/100 - 18s - loss: 0.1958 - acc: 0.9225 - val_loss: 0.1095 - val_acc: 0.9510\n",
            "Epoch 27/50\n",
            "100/100 - 18s - loss: 0.1962 - acc: 0.9180 - val_loss: 0.1093 - val_acc: 0.9520\n",
            "Epoch 28/50\n",
            "100/100 - 18s - loss: 0.2024 - acc: 0.9120 - val_loss: 0.1088 - val_acc: 0.9520\n",
            "Epoch 29/50\n",
            "100/100 - 19s - loss: 0.1813 - acc: 0.9335 - val_loss: 0.1082 - val_acc: 0.9520\n",
            "Epoch 30/50\n",
            "100/100 - 18s - loss: 0.1953 - acc: 0.9250 - val_loss: 0.1080 - val_acc: 0.9530\n",
            "Epoch 31/50\n",
            "100/100 - 18s - loss: 0.1946 - acc: 0.9185 - val_loss: 0.1076 - val_acc: 0.9520\n",
            "Epoch 32/50\n",
            "100/100 - 19s - loss: 0.1834 - acc: 0.9220 - val_loss: 0.1071 - val_acc: 0.9520\n",
            "Epoch 33/50\n",
            "100/100 - 18s - loss: 0.1993 - acc: 0.9230 - val_loss: 0.1065 - val_acc: 0.9510\n",
            "Epoch 34/50\n",
            "100/100 - 18s - loss: 0.1980 - acc: 0.9230 - val_loss: 0.1066 - val_acc: 0.9520\n",
            "Epoch 35/50\n",
            "100/100 - 18s - loss: 0.1853 - acc: 0.9255 - val_loss: 0.1065 - val_acc: 0.9520\n",
            "Epoch 36/50\n",
            "100/100 - 19s - loss: 0.1939 - acc: 0.9245 - val_loss: 0.1063 - val_acc: 0.9520\n",
            "Epoch 37/50\n",
            "100/100 - 18s - loss: 0.1909 - acc: 0.9175 - val_loss: 0.1058 - val_acc: 0.9530\n",
            "Epoch 38/50\n",
            "100/100 - 18s - loss: 0.1796 - acc: 0.9250 - val_loss: 0.1058 - val_acc: 0.9530\n",
            "Epoch 39/50\n",
            "100/100 - 18s - loss: 0.1855 - acc: 0.9255 - val_loss: 0.1055 - val_acc: 0.9520\n",
            "Epoch 40/50\n",
            "100/100 - 18s - loss: 0.1775 - acc: 0.9280 - val_loss: 0.1054 - val_acc: 0.9530\n",
            "Epoch 41/50\n",
            "100/100 - 18s - loss: 0.1846 - acc: 0.9250 - val_loss: 0.1051 - val_acc: 0.9520\n",
            "Epoch 42/50\n",
            "100/100 - 18s - loss: 0.1912 - acc: 0.9210 - val_loss: 0.1044 - val_acc: 0.9530\n",
            "Epoch 43/50\n",
            "100/100 - 18s - loss: 0.1804 - acc: 0.9295 - val_loss: 0.1045 - val_acc: 0.9540\n",
            "Epoch 44/50\n",
            "100/100 - 18s - loss: 0.1777 - acc: 0.9250 - val_loss: 0.1044 - val_acc: 0.9540\n",
            "Epoch 45/50\n",
            "100/100 - 18s - loss: 0.1893 - acc: 0.9155 - val_loss: 0.1035 - val_acc: 0.9530\n",
            "Epoch 46/50\n",
            "100/100 - 18s - loss: 0.1751 - acc: 0.9255 - val_loss: 0.1037 - val_acc: 0.9540\n",
            "Epoch 47/50\n",
            "100/100 - 19s - loss: 0.1925 - acc: 0.9200 - val_loss: 0.1034 - val_acc: 0.9540\n",
            "Epoch 48/50\n",
            "100/100 - 18s - loss: 0.1964 - acc: 0.9180 - val_loss: 0.1035 - val_acc: 0.9540\n",
            "Epoch 49/50\n",
            "100/100 - 18s - loss: 0.1822 - acc: 0.9270 - val_loss: 0.1028 - val_acc: 0.9540\n",
            "Epoch 50/50\n",
            "100/100 - 18s - loss: 0.1776 - acc: 0.9235 - val_loss: 0.1029 - val_acc: 0.9540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9LvsckqosU",
        "outputId": "eee1e66c-fb30-43c2-d4fc-38bfe93a7876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 40,677,249\n",
            "Non-trainable params: 6,835,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FtxcKjJfxL9",
        "outputId": "d587d563-120c-473b-f3b4-1d1733f0a917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUmyohAyBzh"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}